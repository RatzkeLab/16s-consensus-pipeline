########################################
# Winner-takes-all (Plurality) 16S consensus pipeline
########################################

include: "common.smk"

rule all:
    input:
        consensus=consensus_targets_from_checkpoint,
        db=f"{OUT}/consensus_db.fasta",
        report=f"{OUT}/report/summary.html"

########################################
# 1) Pre-filter read check (checkpoint)
########################################
checkpoint check_reads:
    input:
        fq = f"{DEMUX}/{{sample}}.fastq"
    output:
        tsv = f"{OUT}/checks/{{sample}}_pre.tsv"
    log:
        f"logs/check_reads/{{sample}}.log"
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname {output.tsv})" "$(dirname {log})"
        READS=$(awk 'END{{print NR/4}}' {input.fq})
        printf "sample\treads\tthreshold\tstatus\n" > {output.tsv}
        STATUS="PASS"
        if [ "$READS" -lt "{MIN_READS_PRE}" ]; then STATUS="FAIL"; fi
        printf "%s\t%s\t%s\t%s\n" "{wildcards.sample}" "$READS" "{MIN_READS_PRE}" "$STATUS" >> {output.tsv}
        echo "Pre-filter check: $READS reads → $STATUS" > {log}
        """

########################################
# 2) Filtering / trimming (optional via config)
########################################
rule filter_reads:
    input:
        fq = f"{DEMUX}/{{sample}}.fastq"
    output:
        fq = f"{OUT}/filtered/{{sample}}.fastq"
    log:
        f"logs/filter_reads/{{sample}}.log"
    params:
        nanofilt_args = NANOFILT_ARGS
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname {output.fq})" "$(dirname {log})"
        if [ -n "{params.nanofilt_args}" ]; then
          cat {input.fq} \
            | NanoFilt {params.nanofilt_args} \
            > {output.fq} 2> {log}
        else
          cat {input.fq} > {output.fq}
          echo "No filtering applied (pass-through)" > {log}
        fi
        """

########################################
# 3) Post-filter read check (checkpoint)
########################################
checkpoint postfilter_check:
    input:
        fq = f"{OUT}/filtered/{{sample}}.fastq"
    output:
        tsv = f"{OUT}/checks/{{sample}}_post.tsv"
    log:
        f"logs/postfilter_check/{{sample}}.log"
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname {output.tsv})" "$(dirname {log})"
        READS=$(awk 'END{{print NR/4}}' {input.fq})
        printf "sample\treads\tthreshold\tstatus\n" > {output.tsv}
        STATUS="PASS"
        if [ "$READS" -lt "{MIN_READS_POST}" ]; then STATUS="FAIL"; fi
        printf "%s\t%s\t%s\t%s\n" "{wildcards.sample}" "$READS" "{MIN_READS_POST}" "$STATUS" >> {output.tsv}
        echo "Post-filter check: $READS reads → $STATUS" > {log}
        """

########################################
# 4) Collect passed samples (depends on both checks)
########################################
# This is a normal rule, but referenced through a checkpoint in input funcs.
rule collect_passed:
    input:
        pre = expand(f"{OUT}/checks/{{sample}}_pre.tsv", sample=SAMPLES),
        post= expand(f"{OUT}/checks/{{sample}}_post.tsv", sample=SAMPLES)
    output:
        txt = f"{OUT}/checks/passed_samples.txt"
    run:
        import csv, pathlib
        pre_map, post_map = {}, {}
        for p in input.pre:
            row = list(csv.DictReader(open(p, newline=''), delimiter="\t"))[0]
            pre_map[pathlib.Path(p).stem.replace("_pre", "")] = row["status"]
        for p in input.post:
            row = list(csv.DictReader(open(p, newline=''), delimiter="\t"))[0]
            post_map[pathlib.Path(p).stem.replace("_post", "")] = row["status"]
        passed = [s for s in SAMPLES if pre_map.get(s) == "PASS" and post_map.get(s) == "PASS"]
        pathlib.Path(output.txt).parent.mkdir(parents=True, exist_ok=True)
        with open(output.txt, "w") as f:
            for s in sorted(passed):
                f.write(s + "\n")

# Expose as checkpoint so input functions can call checkpoints.collect_passed.get()
checkpoint collect_passed:
    input:
        rules.collect_passed.input
    output:
        txt = rules.collect_passed.output.txt
    run:
        # delegate to the rule by touching the output (already created)
        open(output.txt, "a").close()

########################################
# 5) Subsample reads (~N) — only for PASSED samples
########################################
rule sample_reads:
    input:
        fq = f"{OUT}/filtered/{{sample}}.fastq"
    output:
        fq = f"{OUT}/subsampled/{{sample}}.fastq"
    log:
        f"logs/sample_reads/{{sample}}.log"
    params:
        n = SUBS_N,
        seed = SUBS_SEED
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname {output.fq})" "$(dirname {log})"
        seqtk sample -s {params.seed} {input.fq} {params.n} > {output.fq} 2> {log}
        """

########################################
# 6) Multiple sequence alignment (MAFFT)
########################################
rule align_reads:
    input:
        fq = f"{OUT}/subsampled/{{sample}}.fastq"
    output:
        aln = f"{OUT}/aln/{{sample}}.aln.fasta"
    threads: MAFFT_THREADS
    log:
        f"logs/align_reads/{{sample}}.log"
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname {output.aln})" "$(dirname {log})"
        seqtk seq -A {input.fq} \
          | mafft --thread {threads} --auto - \
          > {output.aln} 2> {log}
        """

########################################
# 7) Plurality consensus; record <50% sites to CSV
########################################
rule consensus_call:
    input:
        aln = f"{OUT}/aln/{{sample}}.aln.fasta"
    output:
        fa   = f"{OUT}/consensus/{{sample}}.fasta",
        csv  = f"{OUT}/consensus_stats/{{sample}}.csv"
    log:
        f"logs/consensus_call/{{sample}}.log"
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname {output.fa})" "$(dirname {output.csv})" "$(dirname {log})"
        python - <<'PY' > {output.fa} 2> {log}
import sys, collections, csv
from pathlib import Path

aln_path = "{input.aln}"
fa_out   = "{output.fa}"
csv_out  = "{output.csv}"
sample   = "{wildcards.sample}"

# read FASTA
seqs = []
with open(aln_path) as f:
    name=None; buf=[]
    for line in f:
        line=line.strip()
        if not line: continue
        if line.startswith(">"):
            if name is not None:
                seqs.append(("".join(buf)).upper())
            name = line[1:]; buf=[]
        else:
            buf.append(line)
    if name is not None:
        seqs.append(("".join(buf)).upper())

if not seqs:
    print(f"ERROR: empty alignment {aln_path}", file=sys.stderr)
    sys.exit(1)

L = len(seqs[0])
if any(len(s)!=L for s in seqs):
    print("ERROR: alignment not equal-length", file=sys.stderr); sys.exit(1)

valid = set("ACGT")
cons = []
low_rows = []  # columns where top < 0.5

for i in range(L):
    col = [s[i] for s in seqs if s[i] in valid]
    n = len(col)
    if n == 0:
        cons.append("N"); continue
    cnt = collections.Counter(col)
    top_base, top_count = cnt.most_common(1)[0]
    prop = top_count / n
    # plurality by definition (no >=0.5 requirement); ties handled below
    # if tie for top, emit N
    # detect tie
    mult = cnt.most_common()
    if len(mult) > 1 and mult[0][1] == mult[1][1]:
        cons.append("N")
        low_rows.append((i+1, "N", mult[0][1], n, mult[0][1]/n, "tie"))
        continue
    cons.append(top_base)
    if prop < 0.5:
        low_rows.append((i+1, top_base, top_count, n, prop, ""))

# write FASTA (strip gaps)
seq = "".join(cons).replace("-", "")
with open(fa_out, "w") as g:
    g.write(f">{sample}\n")
    for j in range(0, len(seq), 80):
        g.write(seq[j:j+80] + "\n")

# write CSV of <50% consensus sites (and ties as flagged)
with open(csv_out, "w", newline="") as g:
    w = csv.writer(g)
    w.writerow(["position","consensus","top_count","column_non_gap","prop_top","note"])
    for r in low_rows:
        w.writerow(r)
PY
        """

########################################
# 8) Build consensus database (FASTA) — only PASSED samples
########################################
rule build_consensus_db:
    input: db_inputs_from_checkpoint
    output:
        db = f"{OUT}/consensus_db.fasta"
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname {output.db})"
        cat {input} > {output.db}
        """

########################################
# 9) Simple HTML report (includes <50% sites summary)
########################################
rule report:
    input: report_inputs_from_checkpoint
    output:
        html = f"{OUT}/report/summary.html"
    log:
        "logs/report/build.log"
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname {output.html})" "$(dirname {log})"
        python - <<'PY' > {output.html} 2> {log}
import os, glob, html, pathlib, csv

title = "{TITLE}"
outdir = "{OUT}"

# collect inputs by suffix
cons = sorted([p for p in {input} if p.endswith(".fasta") and "/consensus/" in p])
stats= sorted([p for p in {input} if p.endswith(".csv") and "/consensus_stats/" in p])
pre  = sorted([p for p in {input} if p.endswith("_pre.tsv")])
post = sorted([p for p in {input} if p.endswith("_post.tsv")])

def read_tsv_one(p):
    row = list(csv.DictReader(open(p, newline=''), delimiter="\t"))[0]
    return row

def fasta_len(p):
    L=0
    with open(p) as f:
        for line in f:
            if not line.startswith(">"):
                L += len(line.strip())
    return L

# maps for counts
pre_map = {pathlib.Path(p).stem.replace("_pre",""): read_tsv_one(p) for p in pre}
post_map= {pathlib.Path(p).stem.replace("_post",""): read_tsv_one(p) for p in post}
low_map = {}
for p in stats:
    s = pathlib.Path(p).stem
    # count rows
    n = sum(1 for _ in open(p)) - 1 if os.path.getsize(p) > 0 else 0
    low_map[s] = max(n, 0)

rows=[]
for p in cons:
    s = pathlib.Path(p).stem
    rows.append((
        s,
        pre_map.get(s,{}).get("reads","NA"),
        pre_map.get(s,{}).get("status","NA"),
        post_map.get(s,{}).get("reads","NA"),
        post_map.get(s,{}).get("status","NA"),
        fasta_len(p),
        low_map.get(s, 0)
    ))
rows.sort()

print("<!doctype html><meta charset='utf-8'>")
print(f"<title>{html.escape(title)}</title>")
print(f"<h1>{html.escape(title)}</h1>")
print("<p>Consensus generated only for samples that passed both read thresholds.</p>")
print("<table border='1' cellspacing='0' cellpadding='4'>")
print("<tr><th>Sample</th><th>Reads pre</th><th>Status</th><th>Reads post</th><th>Status</th><th>Consensus length</th><th>#Sites &lt;50%</th></tr>")
for r in rows:
    s, pre_n, pre_st, post_n, post_st, clen, lowc = r
    print(f"<tr><td>{html.escape(s)}</td><td>{pre_n}</td><td>{pre_st}</td><td>{post_n}</td><td>{post_st}</td><td>{clen}</td><td>{lowc}</td></tr>")
print("</table>")
PY
        """
